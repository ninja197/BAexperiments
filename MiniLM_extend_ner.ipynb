{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninja197/BAexperiments/blob/main/MiniLM_extend_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko69jJHHLu8l",
        "outputId": "822bbf7a-d003-452c-9cfa-6780f8d8170e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.1 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 40.8 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 43.7 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 46.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=196e742692a4234fecb772b82a7a6a288dad2ca65610e856fdeaa4f8f5ccf423\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, huggingface-hub, tokenizers, seqeval, sentencepiece, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 responses-0.18.0 sentencepiece-0.1.96 seqeval-1.2.2 tokenizers-0.12.1 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-eetru2n1\n",
            "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-eetru2n1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.64.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=4004324 sha256=e1899e5ba4846fe39a16d02e3cd569da858d114c991f90a0f960a2031e2fcc7e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u_0mt_j4/wheels/90/a5/44/6bcd83827c8a60628c5ad602f429cd5076bcce5f2a90054947\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, sacremoses, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-6.0 sacremoses-0.0.49 transformers-4.19.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets tokenizers seqeval sentencepiece\n",
        "!pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dUUD-nmSM50Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tokenizers import SentencePieceUnigramTokenizer\n",
        "from transformers import AutoTokenizer, XLMRobertaTokenizer\n",
        "from transformers import AutoModelForTokenClassification, AutoModelForMaskedLM\n",
        "import copy\n",
        "import os\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification, DataCollatorForLanguageModeling\n",
        "import logging\n",
        "import sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkLcDUVC8osn",
        "outputId": "bf06eacd-28c5-4c9b-fd10-9e1237d55806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '/content/drive/MyDrive/sp_model')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d6iuptpLQEkQ"
      },
      "outputs": [],
      "source": [
        "import sentencepiece_model_pb2 as sp_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJYjzGtRrNjP"
      },
      "source": [
        "# Train language-specific SentencePiece and extend tokenizer vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "language = 'arz'"
      ],
      "metadata": {
        "id": "1kqBLZVt3cvc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "2fe83b6b997e42f9b1cc90fbcc075afc",
            "538d8750b23f4ff298abbe4e2ddd6121",
            "0c27fd2bde5d487a972cd22bc380d99c",
            "de3ee0e5db234e329c65857074834147",
            "69e07b069dd348a8bbe55f4a76ea8352",
            "6ec6499039c04ae3b1647173d1fffa32",
            "c02d2d23c07a4e799659d2b4774fdd13",
            "da604ffa67a6401a93e491c46dd84306",
            "1bde92e49df34c19b236a029c3da144a",
            "5abb722ec0be419999d90cf02343cd03",
            "99b3a5bd8d754d30b1cec14564b67f65",
            "3e4bd7b86a68430bb81f1b23cf050213",
            "65c12a4dfbfb41848727b60188b583a8",
            "0aa2981d2bf84533adaeb2fceb0921a9",
            "621067e8385a4fdfa094be4217bd7a70",
            "0258ec32d3f945e48e32f71d15232573",
            "d90c8433cd7b41e0a8de1f6ba1944c64",
            "4cd0eec0f8a94bfd94c1ce4008b6ec50",
            "877f7bf9c3a64491b7473805ba4d61f6",
            "9697eaf35ef247318c9f6512c6b61f9a",
            "ddce01538d184ff79230e418fbe7950b",
            "cdd0db410d704eed8452720c1467f933"
          ]
        },
        "id": "itk4xYChMUc5",
        "outputId": "0a9ad7db-e437-44be-9232-19d5de4eedbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using arz-x-bible-arz-v1.txt to extend vocabulary\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fe83b6b997e42f9b1cc90fbcc075afc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e4bd7b86a68430bb81f1b23cf050213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32000\n",
            "31919\n"
          ]
        }
      ],
      "source": [
        "# Load Bible file names\n",
        "\n",
        "file_name = ''\n",
        "for bible in os.listdir():\n",
        "    code = bible[:3]\n",
        "    if code == language:\n",
        "        file_name = bible\n",
        "        print('Using {} to extend vocabulary'.format(file_name))\n",
        "        logging.info('Using {} to extend vocabulary'.format(file_name))\n",
        "        break\n",
        "file_name =  file_name\n",
        "\n",
        "#Get new tokens from bible\n",
        "spm_tokenizer = SentencePieceUnigramTokenizer()\n",
        "spm_tokenizer.train(\n",
        "    files=[file_name],\n",
        "    vocab_size=32000)\n",
        "\n",
        "new_tokens = spm_tokenizer.get_vocab().keys()\n",
        "\n",
        "#Get tokens in XLM-R\n",
        "orig_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "original_tokens = orig_tokenizer.get_vocab().keys()\n",
        "\n",
        "#Get unique new tokens\n",
        "new_unique_tokens = []\n",
        "for token in new_tokens:\n",
        "    if token not in original_tokens:\n",
        "        new_unique_tokens.append(token)\n",
        "\n",
        "print(len(new_tokens))\n",
        "print(len(new_unique_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Qo_f3RMINBe-"
      },
      "outputs": [],
      "source": [
        "#Load pretrained XLM-R SPM\n",
        "m = sp_model.ModelProto()\n",
        "m.ParseFromString(open('/content/drive/MyDrive/sp_model/sentencepiece.bpe.model', 'rb').read())\n",
        "\n",
        "#Create a raw SentencePiece (no other way to initialize?)\n",
        "raw_piece = copy.deepcopy(m.pieces[50])\n",
        "\n",
        "#Dummy piece added first to hold place for original mask token\n",
        "dummy_mask = copy.deepcopy(raw_piece)\n",
        "dummy_mask.piece = 'DUMMY_MASK'\n",
        "\n",
        "m.pieces.append(dummy_mask)\n",
        "\n",
        "#Add new tokens to SPM and save new model\n",
        "for token in new_unique_tokens:\n",
        "    temp_token = copy.deepcopy(raw_piece)\n",
        "    temp_token.piece = token\n",
        "    m.pieces.append(temp_token)\n",
        "\n",
        "new_spm_save_dir = 'extended_spm.model'\n",
        "!touch extended_spm.model\n",
        "with open(new_spm_save_dir, 'wb') as f:\n",
        "    f.write(m.SerializeToString())\n",
        "\n",
        "#Load extended SPM as tokenizer\n",
        "\n",
        "xlmr_tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "xlmr_tokenizer.vocab_file = new_spm_save_dir\n",
        "xlmr_tokenizer.sp_model.load(xlmr_tokenizer.vocab_file)\n",
        "\n",
        "#Re-align mask token\n",
        "xlmr_tokenizer.fairseq_tokens_to_ids['<mask>'] = xlmr_tokenizer._convert_token_to_id('DUMMY_MASK')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DObxGfxOrjnZ"
      },
      "source": [
        "# Train embeddings on bible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oLaTtNsAx3ED"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "class BibleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, max_len, source_language, target_language, helper_languages, configuration, pretraining_type):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.target_language = target_language\n",
        "        self.helper_languages = helper_languages\n",
        "        self.configuration = configuration\n",
        "        self.pretraining_type = pretraining_type\n",
        "\n",
        "        # Load Bible file names\n",
        "        self.bibles = [bible for bible in os.listdir() if 'txt' in bible]\n",
        "\n",
        "        #Load English examples\n",
        "        self.english_lines = self.read_bible(source_language)\n",
        "        self.target_lines = self.read_bible(target_language)\n",
        "\n",
        "        if self.configuration == 'one':\n",
        "            self.finalized_examples = []\n",
        "            for i in self.target_lines:\n",
        "                if self.target_lines[i]:\n",
        "                    self.finalized_examples.append(self.target_lines[i])\n",
        "        else:\n",
        "            if self.pretraining_type == 'mlm':\n",
        "                self.finalized_examples = self.create_mlm_examples()\n",
        "            elif self.pretraining_type == 'tlm':\n",
        "                self.finalized_examples = self.create_tlm_examples()\n",
        "\n",
        "        random.seed(42)\n",
        "        random.shuffle(self.finalized_examples)\n",
        "\n",
        "        print(self.finalized_examples[:3])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        instance = self.finalized_examples[idx]\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            instance,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            return_token_type_ids= False,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "\n",
        "        return {\n",
        "            'input_ids': enc['input_ids'].squeeze(0),\n",
        "            'attention_mask': enc['attention_mask'].squeeze(0),\n",
        "        }\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.finalized_examples)\n",
        "\n",
        "    def read_bible(self, language, helper=False):\n",
        "\n",
        "        bible_file = None\n",
        "\n",
        "        for bible in self.bibles:\n",
        "            if bible[:3] == language:\n",
        "                bible_file = bible\n",
        "\n",
        "\n",
        "        line_dictionary = defaultdict(None)\n",
        "        with open(bible_file, 'r') as f:\n",
        "            for i, line in enumerate(f,1):\n",
        "                if i >= 26282:\n",
        "                    line_dictionary[i] = line.strip()\n",
        "\n",
        "        return line_dictionary\n",
        "\n",
        "    def create_mlm_examples(self):\n",
        "\n",
        "        #Examples are unaligned. One training instance is one line from the bible in one language\n",
        "        finalized_examples = []\n",
        "\n",
        "        #Are always going to use English and target Bible lines\n",
        "\n",
        "        for i in self.target_lines:\n",
        "            if self.target_lines[i]:\n",
        "                if self.english_lines[i]:\n",
        "                    finalized_examples.append(self.english_lines[i])\n",
        "                    finalized_examples.append(self.target_lines[i])\n",
        "\n",
        "                if self.configuration in ['many-to-one', 'many-to-many']:\n",
        "                    for lang in self.helper_language_lines:\n",
        "                        if lang[i]:\n",
        "                            finalized_examples.append(lang[i])\n",
        "\n",
        "        return finalized_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGIvTzBDrx5G",
        "outputId": "76b32fb6-8443-4c73-f8ef-8b7546190170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['أَفَقَدْ صِرْتُ إِذًا عَدُوًّا لَكُمْ لِأَنِّي أَصْدُقُ لَكُمْ ؟', 'حَتَّى تَعَجَّبَ ٱلْجُمُوعُ إِذْ رَأَوْا ٱلْخُرْسَ يَتَكَلَّمُونَ ، وَٱلشُّلَّ يَصِحُّونَ ، وَٱلْعُرْجَ يَمْشُونَ ، وَٱلْعُمْيَ يُبْصِرُونَ . وَمَجَّدُوا إِلَهَ إِسْرَائِيلَ .', 'وَيَبْكِي تُجَّارُ ٱلْأَرْضِ وَيَنُوحُونَ عَلَيْهَا ، لِأَنَّ بَضَائِعَهُمْ لَا يَشْتَرِيهَا أَحَدٌ فِي مَا بَعْدُ ،']\n"
          ]
        }
      ],
      "source": [
        "# prepare dataset\n",
        "\n",
        "cont_pre_dataset = BibleDataset(\n",
        "    tokenizer=xlmr_tokenizer,\n",
        "    max_len=256,\n",
        "    target_language=language,\n",
        "    source_language='eng',\n",
        "   helper_languages=None,\n",
        "    configuration='one',\n",
        "    pretraining_type='mlm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yjja5nj0x0jq"
      },
      "outputs": [],
      "source": [
        "cont_pre_collator = DataCollatorForLanguageModeling(\n",
        "    mlm=True,\n",
        "    tokenizer=xlmr_tokenizer,\n",
        "    mlm_probability=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Wd7Kd2f_ybKq"
      },
      "outputs": [],
      "source": [
        "# prepare training\n",
        "cont_pre_warmup_steps = int((40 * (cont_pre_dataset.__len__() // (8 * 1 * 4))) * .01)\n",
        "\n",
        "!mkdir temp_directory\n",
        "cont_pre_training_args = TrainingArguments(\n",
        "    output_dir='temp_directory',\n",
        "    num_train_epochs=40,\n",
        "    per_device_train_batch_size=8,\n",
        "    save_steps=5000,\n",
        "    logging_steps=50,\n",
        "    save_total_limit=3,\n",
        "    prediction_loss_only=True,\n",
        "    evaluation_strategy='no',\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=cont_pre_warmup_steps,\n",
        "    dataloader_num_workers=0,\n",
        "    disable_tqdm=False,\n",
        "    gradient_accumulation_steps=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRUQpquuzI5F",
        "outputId": "8b208b38-d45b-450b-f676-88cc93288ee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/microsoft/Multilingual-MiniLM-L12-H384/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/12a5ad52cb7fc5542e16e354fe6eb487f2f87edac63bf85dc238b1236dbaf24c.ccf88548169a21266c411bcf65585ba761d762a9c85fde572f529806fdd94ee2\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"microsoft/Multilingual-MiniLM-L12-H384\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 384,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1536,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"XLMRobertaTokenizer\",\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250037\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/microsoft/Multilingual-MiniLM-L12-H384/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/e1243df19ff0e1975c063fc4c531ba7fdad1ee538e0d94c41a766febfee0c8ab.3d27c3b243133a56a858d62deffdc59141c45422837cf3fde167b873bad92273\n",
            "All model checkpoint weights were used when initializing BertForMaskedLM.\n",
            "\n",
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForMaskedLM(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(250037, 384, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 384)\n",
            "      (token_type_embeddings): Embedding(2, 384)\n",
            "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cls): BertOnlyMLMHead(\n",
            "    (predictions): BertLMPredictionHead(\n",
            "      (transform): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (transform_act_fn): GELUActivation()\n",
            "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (decoder): Linear(in_features=384, out_features=250037, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "BertForMaskedLM(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(281922, 384)\n",
            "      (position_embeddings): Embedding(512, 384)\n",
            "      (token_type_embeddings): Embedding(2, 384)\n",
            "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
            "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cls): BertOnlyMLMHead(\n",
            "    (predictions): BertLMPredictionHead(\n",
            "      (transform): BertPredictionHeadTransform(\n",
            "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
            "        (transform_act_fn): GELUActivation()\n",
            "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
            "      )\n",
            "      (decoder): Linear(in_features=384, out_features=281922, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# load model and extend embeddings\n",
        "\n",
        "cont_pre_model = AutoModelForMaskedLM.from_pretrained('microsoft/Multilingual-MiniLM-L12-H384')\n",
        "print(cont_pre_model)\n",
        "cont_pre_model.resize_token_embeddings(len(xlmr_tokenizer))\n",
        "print(cont_pre_model)\n",
        "logging.info('Resizing token embedding to {}'.format(len(xlmr_tokenizer)))\n",
        "cont_pre_trainer = Trainer(\n",
        "                model=cont_pre_model,\n",
        "                args=cont_pre_training_args,\n",
        "                train_dataset=cont_pre_dataset,\n",
        "                data_collator=cont_pre_collator\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uCesqdEP5OIV",
        "outputId": "260a59a8-2536-4c52-9903-685bed84c5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 7959\n",
            "  Num Epochs = 40\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 9920\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9920' max='9920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9920/9920 1:31:00, Epoch 39/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>12.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>9.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>8.212000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.798600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>7.526600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>7.147000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>6.960600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>6.921500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>6.672700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.729800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>6.527500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>6.422600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>6.398200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>6.244900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>6.247200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>6.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>6.036000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>6.027700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>5.948100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.915100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>5.864700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>5.859500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>5.781500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>5.890900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>5.867400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>5.748500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>5.751200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>5.752900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>5.713600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>5.892600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>5.580400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>5.704900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>5.672300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>5.657200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>5.665100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>5.669000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>5.620300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>5.587200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>5.599000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.620300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>5.530000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>5.494200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>5.496300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>5.546400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>5.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>5.453100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>5.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>5.383200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>5.454500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>5.415100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>5.367300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>5.360400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>5.334900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>5.488700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>5.446000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>5.319600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>5.233100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>5.271600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>5.323600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>5.240500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>5.200400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>5.288700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>5.304600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>5.167000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>5.294300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>5.141300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>5.107800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>5.083300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>5.098500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>5.245400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>5.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>5.137500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>5.077000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>5.075200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>5.128300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>5.065000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>5.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>5.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>5.027900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>5.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>4.975900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>4.931600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>4.997600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>4.992400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>4.996700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>4.888300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>5.005700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>4.869200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>5.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>5.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>4.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>4.931300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>4.860600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>4.904200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>5.017600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>4.834300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>4.865800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>4.896500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>4.839500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>4.916600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>4.844000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>4.773400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>4.866100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>4.854300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>4.796500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>4.857400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>4.847100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>4.774700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>4.854800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>4.854600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>4.776400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>4.771000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>4.709600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>4.800500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>4.852100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>4.737800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>4.687300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>4.712600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>4.725200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>4.777400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>4.667100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>4.667500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>4.671900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>4.646700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>4.735400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>4.745900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>4.746100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>4.701000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>4.761200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>4.678100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>4.625000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>4.690100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>4.702200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>4.714600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>4.579700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>4.645100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>4.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>4.696300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>4.713500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>4.611600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>4.640600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>4.597300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>4.564400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>4.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>4.588100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>4.602600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7350</td>\n",
              "      <td>4.655200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7400</td>\n",
              "      <td>4.678900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7450</td>\n",
              "      <td>4.663000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>4.572900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7550</td>\n",
              "      <td>4.568400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7600</td>\n",
              "      <td>4.569700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7650</td>\n",
              "      <td>4.568200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7700</td>\n",
              "      <td>4.634800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7750</td>\n",
              "      <td>4.536700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7800</td>\n",
              "      <td>4.625400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7850</td>\n",
              "      <td>4.478300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7900</td>\n",
              "      <td>4.598700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7950</td>\n",
              "      <td>4.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>4.668000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8050</td>\n",
              "      <td>4.612600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8100</td>\n",
              "      <td>4.576700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8150</td>\n",
              "      <td>4.592900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8200</td>\n",
              "      <td>4.681100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8250</td>\n",
              "      <td>4.511300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8300</td>\n",
              "      <td>4.575500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8350</td>\n",
              "      <td>4.625800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8400</td>\n",
              "      <td>4.562000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8450</td>\n",
              "      <td>4.606600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>4.592400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8550</td>\n",
              "      <td>4.555700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8600</td>\n",
              "      <td>4.534800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8650</td>\n",
              "      <td>4.509000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8700</td>\n",
              "      <td>4.605400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8750</td>\n",
              "      <td>4.472700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8800</td>\n",
              "      <td>4.497000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8850</td>\n",
              "      <td>4.533600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8900</td>\n",
              "      <td>4.510300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8950</td>\n",
              "      <td>4.582800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>4.534500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9050</td>\n",
              "      <td>4.495500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9100</td>\n",
              "      <td>4.521200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9150</td>\n",
              "      <td>4.499400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9200</td>\n",
              "      <td>4.524500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9250</td>\n",
              "      <td>4.543300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9300</td>\n",
              "      <td>4.501200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9350</td>\n",
              "      <td>4.501200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9400</td>\n",
              "      <td>4.469800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9450</td>\n",
              "      <td>4.650200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>4.522300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9550</td>\n",
              "      <td>4.650700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9600</td>\n",
              "      <td>4.541200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9650</td>\n",
              "      <td>4.474600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9700</td>\n",
              "      <td>4.595900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9750</td>\n",
              "      <td>4.525600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9800</td>\n",
              "      <td>4.511700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9850</td>\n",
              "      <td>4.452500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9900</td>\n",
              "      <td>4.465700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to temp_directory/checkpoint-5000\n",
            "Configuration saved in temp_directory/checkpoint-5000/config.json\n",
            "Model weights saved in temp_directory/checkpoint-5000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Configuration saved in final_model/config.json\n",
            "Model weights saved in final_model/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "# train and save extended model\n",
        "cont_pre_trainer.train()\n",
        "cont_pre_model.save_pretrained('final_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vp_89b_rAjo"
      },
      "source": [
        "# Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QF-rQRE0fwhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1206c9b-3d92-415a-88f3-a482e22ed49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('St.', 'B-ORG'), ('Mary', 'I-ORG'), (\"'s\", 'I-ORG'), ('Catholic', 'I-ORG'), ('Church', 'I-ORG'), ('(', 'I-ORG'), ('Sandusky', 'I-ORG'), (',', 'I-ORG'), ('Ohio', 'I-ORG'), (')', 'I-ORG')]\n",
            "20000\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "\n",
        "class NERDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, file, lang, max_len, tokenizer, assignment):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.assignment = assignment\n",
        "        self.lang = lang\n",
        "\n",
        "        self.create_label2id()\n",
        "\n",
        "        self.examples = self.read_file(file)\n",
        "\n",
        "        print(self.examples[0])\n",
        "        print('----------------------------------------')\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encode(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def create_label2id(self):\n",
        "\n",
        "        ner_tags = [\n",
        "            'B-ORG',\n",
        "            'I-ORG',\n",
        "            'B-PER',\n",
        "            'I-PER',\n",
        "            'B-MISC',\n",
        "            'I-MISC',\n",
        "            'B-LOC',\n",
        "            'I-LOC',\n",
        "            'O'\n",
        "        ]\n",
        "\n",
        "        iter = 0\n",
        "        self.label2id = {}\n",
        "        for tag in ner_tags:\n",
        "            self.label2id[tag] = iter\n",
        "            iter += 1\n",
        "\n",
        "    def read_file(self, file, convert_labels=True):\n",
        "\n",
        "        inps = []\n",
        "\n",
        "        with open(file, 'r') as f:\n",
        "            temp_tokens = []\n",
        "            temp_labels = []\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "\n",
        "                    token = line.strip().split('\\t')\n",
        "                    assert len(token) == 2\n",
        "\n",
        "                    if convert_labels:\n",
        "                        temp_tokens.append(token[0].replace(self.lang + ':', ''))\n",
        "                        temp_labels.append(self.label2id[token[1]])\n",
        "\n",
        "                    else:\n",
        "                        temp_tokens.append(token[0].replace(self.lang + ':', ''))\n",
        "                        temp_labels.append(token[1])\n",
        "\n",
        "                else:\n",
        "                    inps.append((temp_tokens,temp_labels))\n",
        "                    temp_tokens = []\n",
        "                    temp_labels = []\n",
        "        return inps\n",
        "\n",
        "    def encode(self, id):\n",
        "        instance = self.examples[id]\n",
        "\n",
        "\n",
        "        forms = instance[0]\n",
        "        labels = instance[1]\n",
        "\n",
        "        expanded_labels = []\n",
        "        label_mask = []\n",
        "\n",
        "        for i in range(0, len(forms)):\n",
        "\n",
        "            subwords = self.tokenizer.tokenize(forms[i])\n",
        "\n",
        "            if self.assignment == 'first':\n",
        "                expanded_labels.append(labels[i])\n",
        "                for j in range(1, len(subwords)):\n",
        "                    expanded_labels.append(-100)\n",
        "            elif self.assignment == 'all':\n",
        "                for j in range(0,len(subwords)):\n",
        "                    expanded_labels.append(labels[i])\n",
        "                    if j < len(subwords) - 1:\n",
        "                        label_mask.append(0)\n",
        "                    else:\n",
        "                        label_mask.append(1)\n",
        "\n",
        "            elif self.assignment == 'last':\n",
        "                for j in range(0,len(subwords)-1):\n",
        "                    expanded_labels.append(-100)\n",
        "                expanded_labels.append(labels[i])\n",
        "\n",
        "\n",
        "        s1 = ' '.join(forms)\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            s1,\n",
        "            max_length=self.max_len,\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        if len(expanded_labels) > self.max_len:\n",
        "            expanded_labels = expanded_labels[:self.max_len]\n",
        "\n",
        "        enc['labels'] = expanded_labels\n",
        "\n",
        "        return enc\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # x = NERDataset(\n",
        "    #     file='data/ner/rahimi_output/eng/train',\n",
        "    #     max_len=256,\n",
        "    #     tokenizer=None,\n",
        "    #     assignment='last'\n",
        "    # )\n",
        "\n",
        "    inps = []\n",
        "    labels_found = []\n",
        "    lang='en'\n",
        "    with open('/content/drive/MyDrive/en/train') as f:\n",
        "        temp_tokens = []\n",
        "        for line in f:\n",
        "            if line.strip():\n",
        "                token = line.strip().split('\\t')\n",
        "                assert len(token) == 2\n",
        "                temp_tokens.append(\n",
        "                    (token[0].replace(lang + ':', ''), token[1])\n",
        "                )\n",
        "            else:\n",
        "                inps.append(temp_tokens)\n",
        "                temp_tokens = []\n",
        "\n",
        "    print(inps[5])\n",
        "    print(len(inps))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2Pd1dxqzhg95"
      },
      "outputs": [],
      "source": [
        "# filefinder\n",
        "def biblelang2nerlang(bible_lang):\n",
        "    language_mapping = '/content/drive/MyDrive/NER/bible_ner_xlmr_split.txt'\n",
        "    with open(language_mapping, 'r') as f:\n",
        "        for line in f:\n",
        "            data = line.strip().split(',')\n",
        "            if data[1] == bible_lang:\n",
        "                return data[2]\n",
        "\n",
        "def lang_to_ner(lang, split):\n",
        "\n",
        "    ner_dir = '/content/drive/MyDrive/{lang}/{split}'.format(lang=biblelang2nerlang(lang), split=split)\n",
        "\n",
        "    return ner_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ppVrnon_frvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e206a9b-baf5-49f5-bd86-8eb30f176596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['R.H.', 'Saunders', '(', 'St.', 'Lawrence', 'River', ')', '(', '968', 'MW', ')'], [0, 1, 8, 0, 1, 1, 8, 8, 8, 8, 8])\n",
            "----------------------------------------\n",
            "(['انتاجه', 'فى', 'امريكا', 'كندا', 'وبيتسعر', 'غالبن', 'فى', 'الصين', '.'], [8, 8, 6, 6, 8, 8, 8, 6, 8])\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# define training (english) and evaluation dataset\n",
        "ner_train_dataset = NERDataset(file=lang_to_ner('eng', 'train'),\n",
        "                                       lang='en', max_len=256, tokenizer=xlmr_tokenizer,\n",
        "                                       assignment='last')\n",
        "\n",
        "\n",
        "ner_eval_dataset = NERDataset(file=lang_to_ner(language, 'dev'),\n",
        "                          lang=biblelang2nerlang(language), max_len=256, tokenizer=xlmr_tokenizer,\n",
        "                          assignment='last')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MFEXDuqYfsOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a3cb18-eeef-453b-a40a-70da8f0cffe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(['تحويل', 'احمد', 'بن', 'طولون'], [8, 2, 3, 3])\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "ner_test_dataset = NERDataset(file=lang_to_ner(language, 'test'), lang=biblelang2nerlang(language), max_len=256, tokenizer=xlmr_tokenizer, assignment='last')\n",
        "\n",
        "\n",
        "ner_warmup_steps = int((5 * (ner_train_dataset.__len__() // (32 * 4 * 1))) * .01)\n",
        "!mkdir finetuned_ner_model\n",
        "ner_training_args = TrainingArguments(\n",
        "    output_dir= 'finetuned_ner_model',\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    logging_steps=25,\n",
        "    save_total_limit=3,\n",
        "    save_steps=3000,\n",
        "    evaluation_strategy='epoch',\n",
        "    eval_steps=50,\n",
        "    learning_rate=2e-5,\n",
        "    warmup_steps=ner_warmup_steps,\n",
        "    disable_tqdm=False,\n",
        "    gradient_accumulation_steps=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "H4Ao4qJzNB5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3e4be6-85b8-4c34-abfe-899b5b60abf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/arz_model/final_model/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/arz_model/final_model\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 384,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1536,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"tokenizer_class\": \"XLMRobertaTokenizer\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.19.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 281922\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/arz_model/final_model/pytorch_model.bin\n",
            "Some weights of the model checkpoint at /content/drive/MyDrive/arz_model/final_model were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at /content/drive/MyDrive/arz_model/final_model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(281922, 384, padding_idx=0)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "ner_model = AutoModelForTokenClassification.from_pretrained('/content/drive/MyDrive/arz_model/final_model',num_labels=len(ner_train_dataset.label2id))\n",
        "\n",
        "ner_model.resize_token_embeddings(len(xlmr_tokenizer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ha8cfoP5pKBG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from seqeval.metrics import f1_score as seqeval_f1\n",
        "from seqeval.metrics import accuracy_score as seqeval_accuracy\n",
        "\n",
        "\n",
        "def create_id2label_ner():\n",
        "\n",
        "    ner_tags = [\n",
        "        'B-ORG',\n",
        "        'I-ORG',\n",
        "        'B-PER',\n",
        "        'I-PER',\n",
        "        'B-MISC',\n",
        "        'I-MISC',\n",
        "        'B-LOC',\n",
        "        'I-LOC',\n",
        "        'O'\n",
        "    ]\n",
        "\n",
        "    iter = 0\n",
        "    id2label = {}\n",
        "    for tag in ner_tags:\n",
        "        id2label[iter] = tag\n",
        "        iter += 1\n",
        "\n",
        "    return id2label\n",
        "\n",
        "\n",
        "\n",
        "def ner_metrics(eval_pred):\n",
        "\n",
        "    labels = eval_pred.label_ids\n",
        "    preds = eval_pred.predictions.argmax(-1)\n",
        "\n",
        "    corrected_preds = []\n",
        "    corrected_labels = []\n",
        "\n",
        "    id2label = create_id2label_ner()\n",
        "\n",
        "    for i in range(0, len(labels)):\n",
        "        temp_pred = []\n",
        "        temp_label = []\n",
        "        for j in range(0, len(labels[i])):\n",
        "            if labels[i][j] != -100:\n",
        "                temp_label.append(id2label[labels[i][j]])\n",
        "                temp_pred.append(id2label[preds[i][j]])\n",
        "\n",
        "        corrected_labels.append(temp_label)\n",
        "        corrected_preds.append(temp_pred)\n",
        "\n",
        "    acc = seqeval_accuracy(corrected_labels, corrected_preds)\n",
        "    f1 = seqeval_f1(corrected_labels, corrected_preds)\n",
        "\n",
        "    f1 = f1 * 100\n",
        "    acc = acc * 100\n",
        "\n",
        "    logging.info('F1 during training: {}'.format(f1))\n",
        "    logging.info('Accuracy during training: {}'.format(acc))\n",
        "    logging.info('---------------------------------------------')\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Rov422qwoNmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "outputId": "c27d0bab-1b5e-4e92-8046-b7778720e372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 20000\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 3125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 18:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.724200</td>\n",
              "      <td>1.085815</td>\n",
              "      <td>69.776610</td>\n",
              "      <td>34.551495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>0.943449</td>\n",
              "      <td>72.667543</td>\n",
              "      <td>36.426117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.448100</td>\n",
              "      <td>0.847316</td>\n",
              "      <td>75.952694</td>\n",
              "      <td>40.989399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.370400</td>\n",
              "      <td>0.978441</td>\n",
              "      <td>71.353482</td>\n",
              "      <td>33.670034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.367800</td>\n",
              "      <td>0.916222</td>\n",
              "      <td>74.244415</td>\n",
              "      <td>39.007092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to finetuned_ner_model/checkpoint-3000\n",
            "Configuration saved in finetuned_ner_model/checkpoint-3000/config.json\n",
            "Model weights saved in finetuned_ner_model/checkpoint-3000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "***** Running Prediction *****\n",
            "  Num examples = 100\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "ner_collator = DataCollatorForTokenClassification(\n",
        "    tokenizer=xlmr_tokenizer,\n",
        "    padding='longest'\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=ner_model,\n",
        "    data_collator=ner_collator,\n",
        "    args=ner_training_args,\n",
        "    train_dataset=ner_train_dataset,\n",
        "    eval_dataset=ner_eval_dataset,\n",
        "    compute_metrics=ner_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "results = trainer.predict(ner_test_dataset)\n",
        "results = results.metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4OEDoBmRrq6",
        "outputId": "0a707067-eefc-4846-d0c5-60906340521d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_accuracy': 72.88828337874659,\n",
              " 'test_f1': 45.32374100719424,\n",
              " 'test_loss': 0.9322565197944641,\n",
              " 'test_runtime': 0.3773,\n",
              " 'test_samples_per_second': 265.017,\n",
              " 'test_steps_per_second': 34.452}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MiniLM_extend_ner",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1WancTPIprpkwiCoblUw7Q8rP1LmwqnLP",
      "authorship_tag": "ABX9TyMO2mdi1G+IgX1xQ1cLxCrh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fe83b6b997e42f9b1cc90fbcc075afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_538d8750b23f4ff298abbe4e2ddd6121",
              "IPY_MODEL_0c27fd2bde5d487a972cd22bc380d99c",
              "IPY_MODEL_de3ee0e5db234e329c65857074834147"
            ],
            "layout": "IPY_MODEL_69e07b069dd348a8bbe55f4a76ea8352"
          }
        },
        "538d8750b23f4ff298abbe4e2ddd6121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec6499039c04ae3b1647173d1fffa32",
            "placeholder": "​",
            "style": "IPY_MODEL_c02d2d23c07a4e799659d2b4774fdd13",
            "value": "Downloading: 100%"
          }
        },
        "0c27fd2bde5d487a972cd22bc380d99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da604ffa67a6401a93e491c46dd84306",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bde92e49df34c19b236a029c3da144a",
            "value": 5069051
          }
        },
        "de3ee0e5db234e329c65857074834147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abb722ec0be419999d90cf02343cd03",
            "placeholder": "​",
            "style": "IPY_MODEL_99b3a5bd8d754d30b1cec14564b67f65",
            "value": " 4.83M/4.83M [00:00&lt;00:00, 19.0MB/s]"
          }
        },
        "69e07b069dd348a8bbe55f4a76ea8352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec6499039c04ae3b1647173d1fffa32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c02d2d23c07a4e799659d2b4774fdd13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da604ffa67a6401a93e491c46dd84306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bde92e49df34c19b236a029c3da144a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5abb722ec0be419999d90cf02343cd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99b3a5bd8d754d30b1cec14564b67f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e4bd7b86a68430bb81f1b23cf050213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65c12a4dfbfb41848727b60188b583a8",
              "IPY_MODEL_0aa2981d2bf84533adaeb2fceb0921a9",
              "IPY_MODEL_621067e8385a4fdfa094be4217bd7a70"
            ],
            "layout": "IPY_MODEL_0258ec32d3f945e48e32f71d15232573"
          }
        },
        "65c12a4dfbfb41848727b60188b583a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d90c8433cd7b41e0a8de1f6ba1944c64",
            "placeholder": "​",
            "style": "IPY_MODEL_4cd0eec0f8a94bfd94c1ce4008b6ec50",
            "value": "Downloading: 100%"
          }
        },
        "0aa2981d2bf84533adaeb2fceb0921a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_877f7bf9c3a64491b7473805ba4d61f6",
            "max": 615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9697eaf35ef247318c9f6512c6b61f9a",
            "value": 615
          }
        },
        "621067e8385a4fdfa094be4217bd7a70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddce01538d184ff79230e418fbe7950b",
            "placeholder": "​",
            "style": "IPY_MODEL_cdd0db410d704eed8452720c1467f933",
            "value": " 615/615 [00:00&lt;00:00, 15.4kB/s]"
          }
        },
        "0258ec32d3f945e48e32f71d15232573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d90c8433cd7b41e0a8de1f6ba1944c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cd0eec0f8a94bfd94c1ce4008b6ec50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "877f7bf9c3a64491b7473805ba4d61f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9697eaf35ef247318c9f6512c6b61f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddce01538d184ff79230e418fbe7950b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd0db410d704eed8452720c1467f933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}